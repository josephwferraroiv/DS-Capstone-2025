{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKnAdXI9hJbn",
        "outputId": "9d1d192c-469b-4d21-9b9a-ea9f7350b92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install yfinance pandas numpy scikit-learn matplotlib seaborn gym torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mq_O4iMFiCLO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tickers and date range\n",
        "tickers = ['AAPL', 'RIOT', 'PLUG']\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2024-12-31'\n",
        "\n",
        "# Dictionary to store individual DataFrames\n",
        "adj_close_data = {}\n",
        "\n",
        "# Loop through each ticker\n",
        "for ticker in tickers:\n",
        "    data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "    # Keep only 'Date' and 'Adj Close'\n",
        "    df = data[['Adj Close']].reset_index()\n",
        "    df.rename(columns={'Adj Close': f'{ticker}_AdjClose'}, inplace=True)\n",
        "\n",
        "    adj_close_data[ticker] = df\n",
        "\n",
        "# Example: show the first few rows of PLUG\n",
        "# print(adj_close_data['PLUG'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VkyjiJBiMqa",
        "outputId": "a6c3a8ec-531d-46cd-dae9-df29f4ee0db2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Data next"
      ],
      "metadata": {
        "id": "xhu4wrQwjHY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker, df in adj_close_data.items():\n",
        "    # Drop rows with missing values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Convert 'Date' to datetime (in case it isn't already)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Sort chronologically\n",
        "    df.sort_values(by='Date', inplace=True)\n",
        "\n",
        "    # Reset index\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Store back the cleaned DataFrame\n",
        "    adj_close_data[ticker] = df\n",
        "\n",
        "# Preview cleaned data\n",
        "# print(adj_close_data['PLUG'].head())\n"
      ],
      "metadata": {
        "id": "6yQqvAtri4TA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compute technical indicators"
      ],
      "metadata": {
        "id": "AgtzM4ZLj6to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each symbol and compute indicators\n",
        "for ticker, df in adj_close_data.items():\n",
        "    # Use the adjusted close column\n",
        "    price_col = f'{ticker}_AdjClose'\n",
        "\n",
        "    # 20-day Simple Moving Average\n",
        "    df['SMA_20'] = df[price_col].rolling(window=20).mean()\n",
        "\n",
        "    # 10-day Momentum\n",
        "    df['Momentum_10'] = df[price_col] - df[price_col].shift(10)\n",
        "\n",
        "    # 10-day Volatility (standard deviation of past 10 days)\n",
        "    df['Volatility_10'] = df[price_col].rolling(window=10).std()\n",
        "\n",
        "    # Drop rows with NaN values resulting from rolling calculations\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Reset index again after dropping rows\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Example: display indicators for TSLA\n",
        "# print(adj_close_data['TSLA'][['Date', 'TSLA_AdjClose', 'SMA_20', 'Momentum_10', 'Volatility_10']].head())\n"
      ],
      "metadata": {
        "id": "-2bhs37yjkgz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Creation Code"
      ],
      "metadata": {
        "id": "HTWnxBoSz5Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker, df in adj_close_data.items():\n",
        "    price_col = f'{ticker}_AdjClose'\n",
        "\n",
        "    # Compute forward 5-day return\n",
        "    df['Forward_5d_Return'] = (df[price_col].shift(-5) - df[price_col]) / df[price_col]\n",
        "\n",
        "    # Assign labels based on thresholds\n",
        "    def label_return(r):\n",
        "        if r > 0.02:\n",
        "            return 1\n",
        "        elif r < -0.02:\n",
        "            return -1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    df['Label'] = df['Forward_5d_Return'].apply(label_return)\n",
        "\n",
        "    # Drop final rows with NaN from shift(-5)\n",
        "    df.dropna(inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Example: show labeled data for AAPL\n",
        "# print(adj_close_data['AAPL'][['Date', 'AAPL_AdjClose', 'Forward_5d_Return', 'Label']].head(10))\n"
      ],
      "metadata": {
        "id": "nkdYtutWz7GQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training/Testing Set Split"
      ],
      "metadata": {
        "id": "RcYKFuUE0Q7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold training and testing sets\n",
        "train_test_split = {}\n",
        "\n",
        "for ticker, df in adj_close_data.items():\n",
        "    # Ensure 'Date' is datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Split the data\n",
        "    train_df = df[df['Date'] < '2020-01-01'].copy()\n",
        "    test_df = df[df['Date'] >= '2020-01-01'].copy()\n",
        "\n",
        "    # Store in dictionary\n",
        "    train_test_split[ticker] = {\n",
        "        'train': train_df,\n",
        "        'test': test_df\n",
        "    }\n",
        "\n",
        "# Example: view sizes of each split for TSLA\n",
        "# print(\"TSLA Training set size:\", len(train_test_split['TSLA']['train']))\n",
        "# print(\"TSLA Testing set size:\", len(train_test_split['TSLA']['test']))\n"
      ],
      "metadata": {
        "id": "K0h_Ak620QH9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model #1: Random Guessing Model"
      ],
      "metadata": {
        "id": "szbW2qvL0XVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "uwtOMopI1SvD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_guess_results = {}\n",
        "initial_capital = 100000\n",
        "\n",
        "for ticker, splits in train_test_split.items():\n",
        "    test_df = splits['test'].copy()\n",
        "\n",
        "    # Generate random predictions\n",
        "    test_df['Predicted_Action'] = np.random.choice([-1, 0, 1], size=len(test_df))\n",
        "\n",
        "    # Simulate portfolio\n",
        "    in_position = False\n",
        "    entry_price = 0\n",
        "    portfolio_value = float(initial_capital)\n",
        "    portfolio_history = []\n",
        "\n",
        "    for i, row in test_df.iterrows():\n",
        "        action = int(row['Predicted_Action'])\n",
        "        price = float(row[f'{ticker}_AdjClose'])\n",
        "\n",
        "        if action == 1 and not in_position:\n",
        "            entry_price = price\n",
        "            in_position = True\n",
        "\n",
        "        elif action == -1 and in_position:\n",
        "            return_pct = (price - entry_price) / entry_price\n",
        "            portfolio_value *= (1 + return_pct)\n",
        "            in_position = False\n",
        "\n",
        "        portfolio_history.append(portfolio_value)\n",
        "\n",
        "    # If still in a position at the end, close it\n",
        "    if in_position:\n",
        "        final_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
        "        return_pct = (final_price - entry_price) / entry_price\n",
        "        portfolio_value *= (1 + return_pct)\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(test_df['Label'], test_df['Predicted_Action'])\n",
        "    conf_matrix = confusion_matrix(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1])\n",
        "    class_report = classification_report(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1], output_dict=True)\n",
        "\n",
        "    random_guess_results[ticker] = {\n",
        "        'final_portfolio_value': portfolio_value,\n",
        "        'return_pct': (portfolio_value - initial_capital) / initial_capital,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'classification_report': class_report\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- {ticker} [Random Guessing] ---\")\n",
        "    print(f\"Final Portfolio Value: ${portfolio_value:,.2f}\")\n",
        "    print(f\"Total Return: {(portfolio_value - initial_capital) / initial_capital:.2%}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX_pv-VS0WbM",
        "outputId": "d1bde687-d4f8-4f43-e0a0-c9ab5decd204"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-1239231236.py:17: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  action = int(row['Predicted_Action'])\n",
            "/tmp/ipython-input-9-1239231236.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  price = float(row[f'{ticker}_AdjClose'])\n",
            "/tmp/ipython-input-9-1239231236.py:33: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  final_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
            "/tmp/ipython-input-9-1239231236.py:17: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  action = int(row['Predicted_Action'])\n",
            "/tmp/ipython-input-9-1239231236.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  price = float(row[f'{ticker}_AdjClose'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- AAPL [Random Guessing] ---\n",
            "Final Portfolio Value: $214,930.19\n",
            "Total Return: 114.93%\n",
            "Accuracy: 0.3578\n",
            "Confusion Matrix:\n",
            " [[111  93  92]\n",
            " [163 181 164]\n",
            " [153 139 156]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-1239231236.py:33: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  final_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
            "/tmp/ipython-input-9-1239231236.py:17: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  action = int(row['Predicted_Action'])\n",
            "/tmp/ipython-input-9-1239231236.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  price = float(row[f'{ticker}_AdjClose'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RIOT [Random Guessing] ---\n",
            "Final Portfolio Value: $313,744.78\n",
            "Total Return: 213.74%\n",
            "Accuracy: 0.3307\n",
            "Confusion Matrix:\n",
            " [[181 184 191]\n",
            " [ 46  47  47]\n",
            " [195 175 186]]\n",
            "\n",
            "--- PLUG [Random Guessing] ---\n",
            "Final Portfolio Value: $49,288.71\n",
            "Total Return: -50.71%\n",
            "Accuracy: 0.3187\n",
            "Confusion Matrix:\n",
            " [[168 211 192]\n",
            " [ 48  63  54]\n",
            " [183 165 168]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model #2: Buy and Hold Strategy"
      ],
      "metadata": {
        "id": "ktRpkhA21Xj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buy_hold_results = {}\n",
        "initial_capital = 100000\n",
        "\n",
        "for ticker, splits in train_test_split.items():\n",
        "    test_df = splits['test'].copy()\n",
        "\n",
        "    # Get adjusted close prices as floats\n",
        "    entry_price = float(test_df[f'{ticker}_AdjClose'].iloc[0])\n",
        "    exit_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
        "\n",
        "    # Portfolio value after holding through test period\n",
        "    return_pct = (exit_price - entry_price) / entry_price\n",
        "    final_value = initial_capital * (1 + return_pct)\n",
        "\n",
        "    # Simulate constant strategy:\n",
        "    # Buy at start (1), hold (0) throughout, sell at end (-1)\n",
        "    actions = [1] + [0] * (len(test_df) - 2) + [-1]\n",
        "    test_df['Predicted_Action'] = actions\n",
        "\n",
        "    # Evaluate prediction vs true labels\n",
        "    accuracy = accuracy_score(test_df['Label'], test_df['Predicted_Action'])\n",
        "    conf_matrix = confusion_matrix(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1])\n",
        "    class_report = classification_report(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1], output_dict=True)\n",
        "\n",
        "    buy_hold_results[ticker] = {\n",
        "        'final_portfolio_value': final_value,\n",
        "        'return_pct': return_pct,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'classification_report': class_report\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- {ticker} [Buy and Hold] ---\")\n",
        "    print(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
        "    print(f\"Total Return: {return_pct:.2%}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UrqI3db1dqj",
        "outputId": "0fab342d-3ad4-4aac-e8fe-3960c0b1f6c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- AAPL [Buy and Hold] ---\n",
            "Final Portfolio Value: $349,593.26\n",
            "Total Return: 249.59%\n",
            "Accuracy: 0.4058\n",
            "Confusion Matrix:\n",
            " [[  0 296   0]\n",
            " [  1 507   0]\n",
            " [  0 447   1]]\n",
            "\n",
            "--- RIOT [Buy and Hold] ---\n",
            "Final Portfolio Value: $946,721.30\n",
            "Total Return: 846.72%\n",
            "Accuracy: 0.1134\n",
            "Confusion Matrix:\n",
            " [[  1 555   0]\n",
            " [  0 140   0]\n",
            " [  0 555   1]]\n",
            "\n",
            "--- PLUG [Buy and Hold] ---\n",
            "Final Portfolio Value: $79,012.34\n",
            "Total Return: -20.99%\n",
            "Accuracy: 0.1334\n",
            "Confusion Matrix:\n",
            " [[  1 570   0]\n",
            " [  0 165   0]\n",
            " [  0 515   1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-1867281624.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  entry_price = float(test_df[f'{ticker}_AdjClose'].iloc[0])\n",
            "/tmp/ipython-input-10-1867281624.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  exit_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
            "/tmp/ipython-input-10-1867281624.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  entry_price = float(test_df[f'{ticker}_AdjClose'].iloc[0])\n",
            "/tmp/ipython-input-10-1867281624.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  exit_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n",
            "/tmp/ipython-input-10-1867281624.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  entry_price = float(test_df[f'{ticker}_AdjClose'].iloc[0])\n",
            "/tmp/ipython-input-10-1867281624.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  exit_price = float(test_df[f'{ticker}_AdjClose'].iloc[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model #3 - Random Forest Classifier"
      ],
      "metadata": {
        "id": "GR7elDPP5CGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "Xzh8zR-f5fpK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten column names for all tickers and both splits\n",
        "for ticker, splits in train_test_split.items():\n",
        "    for split_name in ['train', 'test']:\n",
        "        df = splits[split_name]\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = ['_'.join(col).strip('_') for col in df.columns.values]\n",
        "        splits[split_name] = df  # reassign flattened DataFrame\n"
      ],
      "metadata": {
        "id": "UXIieDgr7YY9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "random_forest_results = {}\n",
        "initial_capital = 100000\n",
        "features = ['SMA_20', 'Momentum_10', 'Volatility_10']\n",
        "\n",
        "for ticker, splits in train_test_split.items():\n",
        "    train_df = splits['train'].copy()\n",
        "    test_df = splits['test'].copy()\n",
        "\n",
        "    # Drop rows with missing values in features or label\n",
        "    train_df.dropna(subset=features + ['Label'], inplace=True)\n",
        "    test_df.dropna(subset=features + ['Label'], inplace=True)\n",
        "\n",
        "    # Prepare feature matrix and target vector\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df['Label']\n",
        "    X_test = test_df[features]\n",
        "    y_test = test_df['Label']\n",
        "\n",
        "    # Train Random Forest\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict trading actions\n",
        "    test_df['Predicted_Action'] = clf.predict(X_test)\n",
        "\n",
        "    # 🔍 Find adjusted close column dynamically\n",
        "    adj_close_col_candidates = [col for col in test_df.columns if 'AdjClose' in col and ticker in col]\n",
        "    if not adj_close_col_candidates:\n",
        "        raise KeyError(f\"No adjusted close column found for {ticker}\")\n",
        "    adj_close_col = adj_close_col_candidates[0]\n",
        "\n",
        "    # Simulate portfolio\n",
        "    in_position = False\n",
        "    entry_price = 0\n",
        "    portfolio_value = float(initial_capital)\n",
        "    portfolio_history = []\n",
        "\n",
        "    for _, row in test_df.iterrows():\n",
        "        action = int(row['Predicted_Action'])\n",
        "        price = float(row[adj_close_col])\n",
        "\n",
        "        if action == 1 and not in_position:\n",
        "            entry_price = price\n",
        "            in_position = True\n",
        "\n",
        "        elif action == -1 and in_position:\n",
        "            return_pct = (price - entry_price) / entry_price\n",
        "            portfolio_value *= (1 + return_pct)\n",
        "            in_position = False\n",
        "\n",
        "        portfolio_history.append(portfolio_value)\n",
        "\n",
        "    # Close any open position at end\n",
        "    if in_position:\n",
        "        final_price = float(test_df[adj_close_col].iloc[-1])\n",
        "        return_pct = (final_price - entry_price) / entry_price\n",
        "        portfolio_value *= (1 + return_pct)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(test_df['Label'], test_df['Predicted_Action'])\n",
        "    conf_matrix = confusion_matrix(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1])\n",
        "    class_report = classification_report(test_df['Label'], test_df['Predicted_Action'], labels=[-1, 0, 1], output_dict=True)\n",
        "\n",
        "    # Store results\n",
        "    random_forest_results[ticker] = {\n",
        "        'final_portfolio_value': portfolio_value,\n",
        "        'return_pct': (portfolio_value - initial_capital) / initial_capital,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'classification_report': class_report\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n--- {ticker} [Random Forest] ---\")\n",
        "    print(f\"Final Portfolio Value: ${portfolio_value:,.2f}\")\n",
        "    print(f\"Total Return: {(portfolio_value - initial_capital) / initial_capital:.2%}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQXmuZhV5bSp",
        "outputId": "ff7a60e0-4836-4119-ed22-753949e5badc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- AAPL [Random Forest] ---\n",
            "Final Portfolio Value: $456,188.94\n",
            "Total Return: 356.19%\n",
            "Accuracy: 0.3674\n",
            "Confusion Matrix:\n",
            " [[ 19  95 182]\n",
            " [ 22 176 310]\n",
            " [ 13 170 265]]\n",
            "\n",
            "--- RIOT [Random Forest] ---\n",
            "Final Portfolio Value: $514,032.00\n",
            "Total Return: 414.03%\n",
            "Accuracy: 0.4529\n",
            "Confusion Matrix:\n",
            " [[423  25 108]\n",
            " [110   8  22]\n",
            " [404  16 136]]\n",
            "\n",
            "--- PLUG [Random Forest] ---\n",
            "Final Portfolio Value: $126,989.76\n",
            "Total Return: 26.99%\n",
            "Accuracy: 0.4305\n",
            "Confusion Matrix:\n",
            " [[451  24  96]\n",
            " [126   7  32]\n",
            " [415  20  81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reinforcement Learning Model**"
      ],
      "metadata": {
        "id": "w9Z8hjMl8AoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Gym-like Environment"
      ],
      "metadata": {
        "id": "l9DyHLIT1Q50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKpvMFjN83LO",
        "outputId": "5d9528cd-e6d6-4ac1-addd-207e65efbd36"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, df, initial_balance=100000):\n",
        "        super(TradingEnv, self).__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.current_step = 0\n",
        "        self.in_position = False\n",
        "        self.entry_price = 0.0\n",
        "        self.balance = initial_balance\n",
        "\n",
        "        # Observation: [SMA, Momentum, Volatility, Position]\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "        # Actions: 0=Hold, 1=Buy, 2=Sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "    def _get_state(self):\n",
        "        row = self.df.loc[self.current_step]\n",
        "        return np.array([\n",
        "            row['SMA_20'],\n",
        "            row['Momentum_10'],\n",
        "            row['Volatility_10'],\n",
        "            float(self.in_position)\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        done = False\n",
        "        reward = 0\n",
        "        row = self.df.loc[self.current_step]\n",
        "        price = row[[col for col in self.df.columns if 'AdjClose' in col][0]]\n",
        "\n",
        "        # Execute action\n",
        "        if action == 1 and not self.in_position:  # Buy\n",
        "            self.entry_price = price\n",
        "            self.in_position = True\n",
        "        elif action == 2 and self.in_position:  # Sell\n",
        "            reward = (price - self.entry_price) / self.entry_price\n",
        "            self.balance *= (1 + reward)\n",
        "            self.in_position = False\n",
        "        elif action != 0:\n",
        "            reward = -0.001  # small penalty for invalid action (e.g., buying twice)\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            done = True\n",
        "            # Liquidate open position\n",
        "            if self.in_position:\n",
        "                price = self.df[[col for col in self.df.columns if 'AdjClose' in col][0]].iloc[self.current_step]\n",
        "                reward = (price - self.entry_price) / self.entry_price\n",
        "                self.balance *= (1 + reward)\n",
        "                self.in_position = False\n",
        "\n",
        "        return self._get_state(), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.in_position = False\n",
        "        self.entry_price = 0.0\n",
        "        self.balance = self.initial_balance\n",
        "        return self._get_state()\n",
        "\n"
      ],
      "metadata": {
        "id": "sQM-VbOT-AS-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up DQN Agent using PyTorch"
      ],
      "metadata": {
        "id": "63OtmSFF1aFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 64), nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr=1e-3, gamma=0.95, epsilon=1.0, eps_min=0.01, eps_decay=0.995):\n",
        "        self.q_net = DQN(state_dim, action_dim)\n",
        "        self.target_net = DQN(state_dim, action_dim)\n",
        "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
        "        self.memory = deque(maxlen=5000)\n",
        "        self.optimizer = optim.Adam(self.q_net.parameters(), lr=lr)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_min = eps_min\n",
        "        self.eps_decay = eps_decay\n",
        "        self.action_dim = action_dim\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.randrange(self.action_dim)\n",
        "        state = torch.FloatTensor(state).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            q_vals = self.q_net(state)\n",
        "        return torch.argmax(q_vals).item()\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def update(self, batch_size=32):\n",
        "        if len(self.memory) < batch_size:\n",
        "            return\n",
        "\n",
        "        batch = random.sample(self.memory, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.FloatTensor(states)\n",
        "        actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "        rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "        next_states = torch.FloatTensor(next_states)\n",
        "        dones = torch.FloatTensor(dones).unsqueeze(1)\n",
        "\n",
        "        q_vals = self.q_net(states).gather(1, actions)\n",
        "        with torch.no_grad():\n",
        "            q_next = self.target_net(next_states).max(1)[0].unsqueeze(1)\n",
        "            q_target = rewards + self.gamma * q_next * (1 - dones)\n",
        "\n",
        "        loss = self.loss_fn(q_vals, q_target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.eps_min, self.epsilon * self.eps_decay)\n"
      ],
      "metadata": {
        "id": "59GIZnNV-ITJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL Testing Loop"
      ],
      "metadata": {
        "id": "-DvbhanJ3Rca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dqn(env, agent, episodes=50, batch_size=32, target_update_freq=10):\n",
        "    for ep in range(episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action = agent.select_action(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.store((state, action, reward, next_state, done))\n",
        "            agent.update(batch_size)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        agent.decay_epsilon()\n",
        "\n",
        "        if ep % target_update_freq == 0:\n",
        "            agent.update_target_network()\n",
        "\n",
        "        print(f\"Episode {ep+1}, Total Reward: {total_reward:.4f}, Epsilon: {agent.epsilon:.3f}\")\n"
      ],
      "metadata": {
        "id": "KM9bw_L9-NZ6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "def evaluate_dqn(env, agent, ticker, initial_capital=100000):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    portfolio = [env.balance]\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    while not done:\n",
        "        action = agent.select_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        # Store predicted and true label\n",
        "        predictions.append(action)\n",
        "        actual_label = env.df.loc[env.current_step, 'Label'] if env.current_step < len(env.df) else 0\n",
        "        actuals.append(actual_label)\n",
        "\n",
        "        portfolio.append(env.balance)\n",
        "        state = next_state\n",
        "\n",
        "    final_value = env.balance\n",
        "    return_pct = (final_value - initial_capital) / initial_capital\n",
        "    accuracy = accuracy_score(actuals, predictions)\n",
        "    conf_matrix = confusion_matrix(actuals, predictions, labels=[-1, 0, 1])\n",
        "\n",
        "    print(f\"\\n--- {ticker} [DQN] ---\")\n",
        "    print(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
        "    print(f\"Total Return: {return_pct:.2%}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "    return {\n",
        "        'final_portfolio_value': final_value,\n",
        "        'return_pct': return_pct,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'portfolio_history': portfolio,\n",
        "        'predictions': predictions,\n",
        "        'actuals': actuals\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "yMeihBp--Sqh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose one symbol to train on\n",
        "df = train_test_split['PLUG']['train'].copy()\n",
        "\n",
        "# Environment and Agent setup\n",
        "env = TradingEnv(df)\n",
        "agent = DQNAgent(state_dim=4, action_dim=3)\n",
        "\n",
        "# Train\n",
        "train_dqn(env, agent)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_env = TradingEnv(train_test_split['PLUG']['test'].copy())\n",
        "evaluate_dqn(test_env, agent, ticker='PLUG')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4PZsRF9-Zt4",
        "outputId": "d636be92-9753-449a-e143-5dd2a0038b24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-2004072197.py:51: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  states = torch.FloatTensor(states)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Total Reward: -0.5442, Epsilon: 0.995\n",
            "Episode 2, Total Reward: 1.9512, Epsilon: 0.990\n",
            "Episode 3, Total Reward: -1.4274, Epsilon: 0.985\n",
            "Episode 4, Total Reward: 0.7206, Epsilon: 0.980\n",
            "Episode 5, Total Reward: 0.5536, Epsilon: 0.975\n",
            "Episode 6, Total Reward: 0.9986, Epsilon: 0.970\n",
            "Episode 7, Total Reward: 1.1789, Epsilon: 0.966\n",
            "Episode 8, Total Reward: 1.6830, Epsilon: 0.961\n",
            "Episode 9, Total Reward: 0.6365, Epsilon: 0.956\n",
            "Episode 10, Total Reward: 0.2846, Epsilon: 0.951\n",
            "Episode 11, Total Reward: 1.6572, Epsilon: 0.946\n",
            "Episode 12, Total Reward: 0.5723, Epsilon: 0.942\n",
            "Episode 13, Total Reward: 2.0105, Epsilon: 0.937\n",
            "Episode 14, Total Reward: 0.7157, Epsilon: 0.932\n",
            "Episode 15, Total Reward: 1.0392, Epsilon: 0.928\n",
            "Episode 16, Total Reward: -0.2172, Epsilon: 0.923\n",
            "Episode 17, Total Reward: -0.0660, Epsilon: 0.918\n",
            "Episode 18, Total Reward: 0.5443, Epsilon: 0.914\n",
            "Episode 19, Total Reward: 0.4742, Epsilon: 0.909\n",
            "Episode 20, Total Reward: 1.5972, Epsilon: 0.905\n",
            "Episode 21, Total Reward: 0.2829, Epsilon: 0.900\n",
            "Episode 22, Total Reward: -0.5341, Epsilon: 0.896\n",
            "Episode 23, Total Reward: 1.0141, Epsilon: 0.891\n",
            "Episode 24, Total Reward: 0.4953, Epsilon: 0.887\n",
            "Episode 25, Total Reward: 0.8154, Epsilon: 0.882\n",
            "Episode 26, Total Reward: -0.8201, Epsilon: 0.878\n",
            "Episode 27, Total Reward: 0.4102, Epsilon: 0.873\n",
            "Episode 28, Total Reward: 1.0454, Epsilon: 0.869\n",
            "Episode 29, Total Reward: 1.6213, Epsilon: 0.865\n",
            "Episode 30, Total Reward: 1.6464, Epsilon: 0.860\n",
            "Episode 31, Total Reward: 1.0283, Epsilon: 0.856\n",
            "Episode 32, Total Reward: -0.4393, Epsilon: 0.852\n",
            "Episode 33, Total Reward: -1.6604, Epsilon: 0.848\n",
            "Episode 34, Total Reward: 1.0604, Epsilon: 0.843\n",
            "Episode 35, Total Reward: 0.1165, Epsilon: 0.839\n",
            "Episode 36, Total Reward: -0.0618, Epsilon: 0.835\n",
            "Episode 37, Total Reward: -0.2756, Epsilon: 0.831\n",
            "Episode 38, Total Reward: 0.4658, Epsilon: 0.827\n",
            "Episode 39, Total Reward: 3.0989, Epsilon: 0.822\n",
            "Episode 40, Total Reward: -0.0948, Epsilon: 0.818\n",
            "Episode 41, Total Reward: -0.7351, Epsilon: 0.814\n",
            "Episode 42, Total Reward: 1.4857, Epsilon: 0.810\n",
            "Episode 43, Total Reward: 0.7302, Epsilon: 0.806\n",
            "Episode 44, Total Reward: 0.1639, Epsilon: 0.802\n",
            "Episode 45, Total Reward: -1.3078, Epsilon: 0.798\n",
            "Episode 46, Total Reward: 0.4213, Epsilon: 0.794\n",
            "Episode 47, Total Reward: 0.4484, Epsilon: 0.790\n",
            "Episode 48, Total Reward: 0.3555, Epsilon: 0.786\n",
            "Episode 49, Total Reward: 0.7717, Epsilon: 0.782\n",
            "Episode 50, Total Reward: -0.3161, Epsilon: 0.778\n",
            "\n",
            "--- PLUG [DQN] ---\n",
            "Final Portfolio Value: $198,337.78\n",
            "Total Return: 98.34%\n",
            "Accuracy: 0.1751\n",
            "Confusion Matrix:\n",
            " [[  0 271 158]\n",
            " [  0  87  38]\n",
            " [  0 250 132]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'final_portfolio_value': np.float64(198337.77928468536),\n",
              " 'return_pct': np.float64(0.9833777928468536),\n",
              " 'accuracy': 0.1750599520383693,\n",
              " 'conf_matrix': array([[  0, 271, 158],\n",
              "        [  0,  87,  38],\n",
              "        [  0, 250, 132]]),\n",
              " 'portfolio_history': [100000,\n",
              "  100000,\n",
              "  100000,\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(117901.23216045865),\n",
              "  np.float64(116745.33880824519),\n",
              "  np.float64(116745.33880824519),\n",
              "  np.float64(116745.33880824519),\n",
              "  np.float64(115911.45091564277),\n",
              "  np.float64(115911.45091564277),\n",
              "  np.float64(115911.45091564277),\n",
              "  np.float64(115911.45091564277),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(104642.28047734866),\n",
              "  np.float64(116038.96607944317),\n",
              "  np.float64(116038.96607944317),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114998.25886488204),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(114524.03968362327),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(126259.7174344595),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(124402.94985305428),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(122463.49128538095),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(119045.89531266005),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(114959.64906148521),\n",
              "  np.float64(111040.563627449),\n",
              "  np.float64(111040.563627449),\n",
              "  np.float64(111040.563627449),\n",
              "  np.float64(111040.563627449),\n",
              "  np.float64(114332.28207055657),\n",
              "  np.float64(114332.28207055657),\n",
              "  np.float64(114332.28207055657),\n",
              "  np.float64(114332.28207055657),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(116241.35871006697),\n",
              "  np.float64(166744.77573864663),\n",
              "  np.float64(166744.77573864663),\n",
              "  np.float64(180149.3465100144),\n",
              "  np.float64(180149.3465100144),\n",
              "  np.float64(197570.3648721983),\n",
              "  np.float64(197570.3648721983),\n",
              "  np.float64(200954.86462768787),\n",
              "  np.float64(200954.86462768787),\n",
              "  np.float64(200954.86462768787),\n",
              "  np.float64(200954.86462768787),\n",
              "  np.float64(200954.86462768787),\n",
              "  np.float64(210015.265743693),\n",
              "  np.float64(210015.265743693),\n",
              "  np.float64(210015.265743693),\n",
              "  np.float64(210015.265743693),\n",
              "  np.float64(210015.265743693),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(218562.38429928912),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(219143.6805545268),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(247017.23446946897),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(257757.1194680637),\n",
              "  np.float64(271539.8244472568),\n",
              "  np.float64(271539.8244472568),\n",
              "  np.float64(271539.8244472568),\n",
              "  np.float64(271539.8244472568),\n",
              "  np.float64(286321.644638272),\n",
              "  np.float64(286321.644638272),\n",
              "  np.float64(286321.644638272),\n",
              "  np.float64(286321.644638272),\n",
              "  np.float64(325249.7357233401),\n",
              "  np.float64(325249.7357233401),\n",
              "  np.float64(325249.7357233401),\n",
              "  np.float64(325249.7357233401),\n",
              "  np.float64(325249.7357233401),\n",
              "  np.float64(323918.3098909195),\n",
              "  np.float64(323918.3098909195),\n",
              "  np.float64(323918.3098909195),\n",
              "  np.float64(321942.0232566788),\n",
              "  np.float64(321942.0232566788),\n",
              "  np.float64(321942.0232566788),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(325625.07640475006),\n",
              "  np.float64(396559.55935740843),\n",
              "  np.float64(396559.55935740843),\n",
              "  np.float64(396559.55935740843),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(420740.011490334),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(400376.21034216124),\n",
              "  np.float64(432568.07163274946),\n",
              "  np.float64(432568.07163274946),\n",
              "  np.float64(432568.07163274946),\n",
              "  np.float64(432568.07163274946),\n",
              "  np.float64(452931.6829890342),\n",
              "  np.float64(452931.6829890342),\n",
              "  np.float64(452931.6829890342),\n",
              "  np.float64(452931.6829890342),\n",
              "  np.float64(463528.2479791399),\n",
              "  np.float64(463528.2479791399),\n",
              "  np.float64(463528.2479791399),\n",
              "  np.float64(463528.2479791399),\n",
              "  np.float64(437342.3929849436),\n",
              "  np.float64(437342.3929849436),\n",
              "  np.float64(437342.3929849436),\n",
              "  np.float64(437342.3929849436),\n",
              "  np.float64(437342.3929849436),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(438554.98951026594),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(442009.25306449394),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(433274.71468129015),\n",
              "  np.float64(372787.3257996912),\n",
              "  np.float64(372787.3257996912),\n",
              "  np.float64(372787.3257996912),\n",
              "  np.float64(311319.3583730717),\n",
              "  np.float64(311319.3583730717),\n",
              "  np.float64(311319.3583730717),\n",
              "  np.float64(301892.6505836599),\n",
              "  np.float64(301892.6505836599),\n",
              "  np.float64(301892.6505836599),\n",
              "  np.float64(301892.6505836599),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(296188.284577921),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(277308.9995553656),\n",
              "  np.float64(241348.94500028613),\n",
              "  np.float64(241348.94500028613),\n",
              "  np.float64(241348.94500028613),\n",
              "  np.float64(241348.94500028613),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(223717.36095675718),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(221523.2947693894),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(226491.26972174234),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(229084.97349001552),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(209447.0956728892),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(189703.35130329346),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(200496.55899642533),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(202051.9515609127),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(213836.3664043131),\n",
              "  np.float64(196395.51410467972),\n",
              "  np.float64(196395.51410467972),\n",
              "  np.float64(196395.51410467972),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(209526.3809508246),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(217705.37105214444),\n",
              "  np.float64(212097.80586680424),\n",
              "  np.float64(212097.80586680424),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(218929.17817557973),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(234380.88203966155),\n",
              "  np.float64(269292.33385273546),\n",
              "  np.float64(269292.33385273546),\n",
              "  np.float64(269292.33385273546),\n",
              "  np.float64(265104.76977897907),\n",
              "  np.float64(265104.76977897907),\n",
              "  np.float64(257467.37883778897),\n",
              "  np.float64(257467.37883778897),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(252226.4791870256),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(261249.69410674815),\n",
              "  np.float64(228399.03901208105),\n",
              "  np.float64(228399.03901208105),\n",
              "  np.float64(228399.03901208105),\n",
              "  np.float64(232426.3991900611),\n",
              "  np.float64(232426.3991900611),\n",
              "  np.float64(232426.3991900611),\n",
              "  np.float64(232426.3991900611),\n",
              "  np.float64(232426.3991900611),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(225499.77315566014),\n",
              "  np.float64(218487.51352280265),\n",
              "  np.float64(218487.51352280265),\n",
              "  np.float64(218487.51352280265),\n",
              "  np.float64(218487.51352280265),\n",
              "  np.float64(218487.51352280265),\n",
              "  np.float64(222821.67255942075),\n",
              "  np.float64(222821.67255942075),\n",
              "  np.float64(222821.67255942075),\n",
              "  np.float64(222821.67255942075),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(211710.26441456185),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(206200.73422820662),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(174315.99017159178),\n",
              "  np.float64(180938.4818863239),\n",
              "  np.float64(180938.4818863239),\n",
              "  np.float64(180938.4818863239),\n",
              "  np.float64(180938.4818863239),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(170034.6227820242),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(192540.3102440127),\n",
              "  np.float64(207397.27549779986),\n",
              "  np.float64(207397.27549779986),\n",
              "  np.float64(207397.27549779986),\n",
              "  np.float64(207397.27549779986),\n",
              "  np.float64(216069.1966694041),\n",
              "  np.float64(216069.1966694041),\n",
              "  np.float64(216069.1966694041),\n",
              "  np.float64(216069.1966694041),\n",
              "  np.float64(242067.64140144634),\n",
              "  np.float64(242067.64140144634),\n",
              "  np.float64(224970.22591062414),\n",
              "  np.float64(224970.22591062414),\n",
              "  np.float64(224970.22591062414),\n",
              "  np.float64(224970.22591062414),\n",
              "  np.float64(224970.22591062414),\n",
              "  np.float64(231281.838479507),\n",
              "  np.float64(231281.838479507),\n",
              "  np.float64(231281.838479507),\n",
              "  np.float64(231281.838479507),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(239000.19616624838),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(165613.22092328404),\n",
              "  np.float64(171557.78280274887),\n",
              "  np.float64(171557.78280274887),\n",
              "  np.float64(171557.78280274887),\n",
              "  np.float64(171557.78280274887),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(192804.71832370386),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(170318.00576786645),\n",
              "  np.float64(160351.65307070172),\n",
              "  np.float64(160351.65307070172),\n",
              "  np.float64(160351.65307070172),\n",
              "  np.float64(135837.61986794404),\n",
              "  np.float64(135837.61986794404),\n",
              "  np.float64(135837.61986794404),\n",
              "  np.float64(135837.61986794404),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(151555.73343261867),\n",
              "  np.float64(214061.7726917802),\n",
              "  np.float64(214061.7726917802),\n",
              "  np.float64(214061.7726917802),\n",
              "  np.float64(214061.7726917802),\n",
              "  np.float64(214061.7726917802),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(205664.1969453168),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(206857.6031593162),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(201004.11470626536),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(188692.76208786853),\n",
              "  np.float64(181531.74208607132),\n",
              "  np.float64(181531.74208607132),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(176496.1923494983),\n",
              "  np.float64(184176.47631914626),\n",
              "  np.float64(184176.47631914626),\n",
              "  np.float64(184176.47631914626),\n",
              "  np.float64(184176.47631914626),\n",
              "  np.float64(184176.47631914626),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(189985.1168720501),\n",
              "  np.float64(188969.15195313003),\n",
              "  np.float64(188969.15195313003),\n",
              "  np.float64(188969.15195313003),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(183418.03287098298),\n",
              "  np.float64(147944.2348016222),\n",
              "  np.float64(147944.2348016222),\n",
              "  np.float64(149063.47930494076),\n",
              "  np.float64(149063.47930494076),\n",
              "  np.float64(149063.47930494076),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(151198.76829990512),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(156303.00065440647),\n",
              "  np.float64(134094.04514987025),\n",
              "  np.float64(134094.04514987025),\n",
              "  np.float64(134094.04514987025),\n",
              "  np.float64(134094.04514987025),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(142134.73490703676),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(132294.64689832667),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(127363.53132986523),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(121073.98011763343),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(133121.14524781983),\n",
              "  np.float64(145006.95321496535),\n",
              "  np.float64(145006.95321496535),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(142082.88640703654),\n",
              "  np.float64(159692.73760679123),\n",
              "  np.float64(159692.73760679123),\n",
              "  np.float64(159692.73760679123),\n",
              "  np.float64(159692.73760679123),\n",
              "  np.float64(159692.73760679123),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(177047.48156545416),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(130316.38086818185),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126210.73799046056),\n",
              "  np.float64(126890.20297319256),\n",
              "  np.float64(126890.20297319256),\n",
              "  np.float64(126890.20297319256),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(127226.33563214794),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(145685.07725162912),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(146856.18366569869),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(104755.76352267849),\n",
              "  np.float64(115925.68288736766),\n",
              "  np.float64(115925.68288736766),\n",
              "  np.float64(115925.68288736766),\n",
              "  np.float64(115925.68288736766),\n",
              "  np.float64(137733.4913922153),\n",
              "  np.float64(137733.4913922153),\n",
              "  np.float64(137733.4913922153),\n",
              "  np.float64(132860.85641982552),\n",
              "  np.float64(132860.85641982552),\n",
              "  np.float64(132860.85641982552),\n",
              "  np.float64(132860.85641982552),\n",
              "  np.float64(140007.3990717983),\n",
              "  np.float64(140007.3990717983),\n",
              "  np.float64(140007.3990717983),\n",
              "  np.float64(140007.3990717983),\n",
              "  np.float64(140007.3990717983),\n",
              "  ...],\n",
              " 'predictions': [1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  ...],\n",
              " 'actuals': [np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(-1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  ...]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}